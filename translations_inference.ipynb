{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Op type not registered 'NormalizeUTF8' in binary running on DESKTOP-B908L0E. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:4215\u001b[0m, in \u001b[0;36mGraph._get_op_def\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m   4214\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 4215\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_op_def_cache[\u001b[39mtype\u001b[39;49m]\n\u001b[0;32m   4216\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'NormalizeUTF8'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:966\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 966\u001b[0m   loader \u001b[39m=\u001b[39m Loader(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0;32m    967\u001b[0m                   ckpt_options, options, filters)\n\u001b[0;32m    968\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mNotFoundError \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:157\u001b[0m, in \u001b[0;36mLoader.__init__\u001b[1;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_export_dir \u001b[39m=\u001b[39m export_dir\n\u001b[0;32m    156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_functions \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 157\u001b[0m     function_deserialization\u001b[39m.\u001b[39;49mload_function_def_library(\n\u001b[0;32m    158\u001b[0m         library\u001b[39m=\u001b[39;49mmeta_graph\u001b[39m.\u001b[39;49mgraph_def\u001b[39m.\u001b[39;49mlibrary,\n\u001b[0;32m    159\u001b[0m         saved_object_graph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_proto,\n\u001b[0;32m    160\u001b[0m         wrapper_function\u001b[39m=\u001b[39;49m_WrapperFunction))\n\u001b[0;32m    161\u001b[0m \u001b[39m# Store a set of all concrete functions that have been set up with\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39m# captures.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py:416\u001b[0m, in \u001b[0;36mload_function_def_library\u001b[1;34m(library, saved_object_graph, load_shared_name_suffix, wrapper_function)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[39mwith\u001b[39;00m graph\u001b[39m.\u001b[39mas_default():\n\u001b[1;32m--> 416\u001b[0m   func_graph \u001b[39m=\u001b[39m function_def_lib\u001b[39m.\u001b[39;49mfunction_def_to_graph(\n\u001b[0;32m    417\u001b[0m       fdef,\n\u001b[0;32m    418\u001b[0m       structured_input_signature\u001b[39m=\u001b[39;49mstructured_input_signature,\n\u001b[0;32m    419\u001b[0m       structured_outputs\u001b[39m=\u001b[39;49mstructured_outputs)\n\u001b[0;32m    420\u001b[0m \u001b[39m# Restores gradients for function-call ops (not the same as ops that use\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[39m# custom gradients)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\function_def_to_graph.py:85\u001b[0m, in \u001b[0;36mfunction_def_to_graph\u001b[1;34m(fdef, structured_input_signature, structured_outputs, input_shapes, propagate_device_spec)\u001b[0m\n\u001b[0;32m     83\u001b[0m         input_shapes\u001b[39m.\u001b[39mappend(input_shape)\n\u001b[1;32m---> 85\u001b[0m graph_def, nested_to_flat_tensor_name \u001b[39m=\u001b[39m function_def_to_graph_def(\n\u001b[0;32m     86\u001b[0m     fdef, input_shapes)\n\u001b[0;32m     88\u001b[0m \u001b[39mwith\u001b[39;00m func_graph\u001b[39m.\u001b[39mas_default():\n\u001b[0;32m     89\u001b[0m   \u001b[39m# Add all function nodes to the graph.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\function_def_to_graph.py:256\u001b[0m, in \u001b[0;36mfunction_def_to_graph_def\u001b[1;34m(fdef, input_shapes)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 256\u001b[0m   op_def \u001b[39m=\u001b[39m default_graph\u001b[39m.\u001b[39;49m_get_op_def(node_def\u001b[39m.\u001b[39;49mop)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[39mfor\u001b[39;00m attr \u001b[39min\u001b[39;00m op_def\u001b[39m.\u001b[39mattr:\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:4219\u001b[0m, in \u001b[0;36mGraph._get_op_def\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m   4218\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_graph\u001b[39m.\u001b[39mget() \u001b[39mas\u001b[39;00m c_graph:\n\u001b[1;32m-> 4219\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39;49mTF_GraphGetOpDef(c_graph, compat\u001b[39m.\u001b[39;49mas_bytes(\u001b[39mtype\u001b[39;49m),\n\u001b[0;32m   4220\u001b[0m                                      buf)\n\u001b[0;32m   4221\u001b[0m data \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39mTF_GetBuffer(buf)\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Op type not registered 'NormalizeUTF8' in binary running on DESKTOP-B908L0E. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# tf.saved_model.LoadOptions(experimental_io_device=)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[39m# tf.saved_model\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m reloaded \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49msaved_model\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mtranslator\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:836\u001b[0m, in \u001b[0;36mload\u001b[1;34m(export_dir, tags, options)\u001b[0m\n\u001b[0;32m    834\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(export_dir, os\u001b[39m.\u001b[39mPathLike):\n\u001b[0;32m    835\u001b[0m   export_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mfspath(export_dir)\n\u001b[1;32m--> 836\u001b[0m result \u001b[39m=\u001b[39m load_partial(export_dir, \u001b[39mNone\u001b[39;49;00m, tags, options)[\u001b[39m\"\u001b[39m\u001b[39mroot\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    837\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:969\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m    966\u001b[0m   loader \u001b[39m=\u001b[39m Loader(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0;32m    967\u001b[0m                   ckpt_options, options, filters)\n\u001b[0;32m    968\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mNotFoundError \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 969\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    970\u001b[0m       \u001b[39mstr\u001b[39m(err) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m You may be trying to load on a different device \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    971\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mfrom the computational device. Consider setting the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    972\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    973\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mto the io_device such as \u001b[39m\u001b[39m'\u001b[39m\u001b[39m/job:localhost\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    974\u001b[0m root \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39mget(\u001b[39m0\u001b[39m)\n\u001b[0;32m    975\u001b[0m root\u001b[39m.\u001b[39mgraph_debug_info \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39madjust_debug_info_func_names(debug_info)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Op type not registered 'NormalizeUTF8' in binary running on DESKTOP-B908L0E. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'."
     ]
    }
   ],
   "source": [
    "# tf.saved_model.LoadOptions(experimental_io_device=)\n",
    "\n",
    "# tf.saved_model\n",
    "reloaded = tf.saved_model.load('translator')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Op type not registered 'NormalizeUTF8' in binary running on DESKTOP-B908L0E. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:4215\u001b[0m, in \u001b[0;36mGraph._get_op_def\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m   4214\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 4215\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_op_def_cache[\u001b[39mtype\u001b[39;49m]\n\u001b[0;32m   4216\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'NormalizeUTF8'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:966\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 966\u001b[0m   loader \u001b[39m=\u001b[39m Loader(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0;32m    967\u001b[0m                   ckpt_options, options, filters)\n\u001b[0;32m    968\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mNotFoundError \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:157\u001b[0m, in \u001b[0;36mLoader.__init__\u001b[1;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_export_dir \u001b[39m=\u001b[39m export_dir\n\u001b[0;32m    156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_functions \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 157\u001b[0m     function_deserialization\u001b[39m.\u001b[39;49mload_function_def_library(\n\u001b[0;32m    158\u001b[0m         library\u001b[39m=\u001b[39;49mmeta_graph\u001b[39m.\u001b[39;49mgraph_def\u001b[39m.\u001b[39;49mlibrary,\n\u001b[0;32m    159\u001b[0m         saved_object_graph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_proto,\n\u001b[0;32m    160\u001b[0m         wrapper_function\u001b[39m=\u001b[39;49m_WrapperFunction))\n\u001b[0;32m    161\u001b[0m \u001b[39m# Store a set of all concrete functions that have been set up with\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39m# captures.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py:416\u001b[0m, in \u001b[0;36mload_function_def_library\u001b[1;34m(library, saved_object_graph, load_shared_name_suffix, wrapper_function)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[39mwith\u001b[39;00m graph\u001b[39m.\u001b[39mas_default():\n\u001b[1;32m--> 416\u001b[0m   func_graph \u001b[39m=\u001b[39m function_def_lib\u001b[39m.\u001b[39;49mfunction_def_to_graph(\n\u001b[0;32m    417\u001b[0m       fdef,\n\u001b[0;32m    418\u001b[0m       structured_input_signature\u001b[39m=\u001b[39;49mstructured_input_signature,\n\u001b[0;32m    419\u001b[0m       structured_outputs\u001b[39m=\u001b[39;49mstructured_outputs)\n\u001b[0;32m    420\u001b[0m \u001b[39m# Restores gradients for function-call ops (not the same as ops that use\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[39m# custom gradients)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\function_def_to_graph.py:85\u001b[0m, in \u001b[0;36mfunction_def_to_graph\u001b[1;34m(fdef, structured_input_signature, structured_outputs, input_shapes, propagate_device_spec)\u001b[0m\n\u001b[0;32m     83\u001b[0m         input_shapes\u001b[39m.\u001b[39mappend(input_shape)\n\u001b[1;32m---> 85\u001b[0m graph_def, nested_to_flat_tensor_name \u001b[39m=\u001b[39m function_def_to_graph_def(\n\u001b[0;32m     86\u001b[0m     fdef, input_shapes)\n\u001b[0;32m     88\u001b[0m \u001b[39mwith\u001b[39;00m func_graph\u001b[39m.\u001b[39mas_default():\n\u001b[0;32m     89\u001b[0m   \u001b[39m# Add all function nodes to the graph.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\function_def_to_graph.py:256\u001b[0m, in \u001b[0;36mfunction_def_to_graph_def\u001b[1;34m(fdef, input_shapes)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 256\u001b[0m   op_def \u001b[39m=\u001b[39m default_graph\u001b[39m.\u001b[39;49m_get_op_def(node_def\u001b[39m.\u001b[39;49mop)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[39mfor\u001b[39;00m attr \u001b[39min\u001b[39;00m op_def\u001b[39m.\u001b[39mattr:\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:4219\u001b[0m, in \u001b[0;36mGraph._get_op_def\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m   4218\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_graph\u001b[39m.\u001b[39mget() \u001b[39mas\u001b[39;00m c_graph:\n\u001b[1;32m-> 4219\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39;49mTF_GraphGetOpDef(c_graph, compat\u001b[39m.\u001b[39;49mas_bytes(\u001b[39mtype\u001b[39;49m),\n\u001b[0;32m   4220\u001b[0m                                      buf)\n\u001b[0;32m   4221\u001b[0m data \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39mTF_GetBuffer(buf)\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Op type not registered 'NormalizeUTF8' in binary running on DESKTOP-B908L0E. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39m#(experimental_io_device='DESKTOP-B908L0E')\u001b[39;00m\n\u001b[0;32m      3\u001b[0m loader\u001b[39m.\u001b[39mexperimental_io_device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDESKTOP-B908L0E\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m reloaded \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49msaved_model\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mtranslator\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:836\u001b[0m, in \u001b[0;36mload\u001b[1;34m(export_dir, tags, options)\u001b[0m\n\u001b[0;32m    834\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(export_dir, os\u001b[39m.\u001b[39mPathLike):\n\u001b[0;32m    835\u001b[0m   export_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mfspath(export_dir)\n\u001b[1;32m--> 836\u001b[0m result \u001b[39m=\u001b[39m load_partial(export_dir, \u001b[39mNone\u001b[39;49;00m, tags, options)[\u001b[39m\"\u001b[39m\u001b[39mroot\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    837\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:969\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m    966\u001b[0m   loader \u001b[39m=\u001b[39m Loader(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0;32m    967\u001b[0m                   ckpt_options, options, filters)\n\u001b[0;32m    968\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mNotFoundError \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 969\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    970\u001b[0m       \u001b[39mstr\u001b[39m(err) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m You may be trying to load on a different device \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    971\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mfrom the computational device. Consider setting the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    972\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    973\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mto the io_device such as \u001b[39m\u001b[39m'\u001b[39m\u001b[39m/job:localhost\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    974\u001b[0m root \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39mget(\u001b[39m0\u001b[39m)\n\u001b[0;32m    975\u001b[0m root\u001b[39m.\u001b[39mgraph_debug_info \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39madjust_debug_info_func_names(debug_info)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Op type not registered 'NormalizeUTF8' in binary running on DESKTOP-B908L0E. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'."
     ]
    }
   ],
   "source": [
    "loader=tf.saved_model.LoadOptions()\n",
    "#(experimental_io_device='DESKTOP-B908L0E')\n",
    "loader.experimental_io_device='DESKTOP-B908L0E'\n",
    "reloaded = tf.saved_model.load('translator')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
